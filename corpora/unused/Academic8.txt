We compare in this paper several feature selection methods for the Naive Bayes Classifier (NBC) when the data under study are described by a large number of redundant binary indicators. Wrapper approaches guided by the NBC estimation of the classification error probability outperform filter approaches while retaining a reasonable computational cost. 1 Introduction We consider in this paper application contexts in which a large body of expert knowledge is available as a series of simple and low level parametric scores. The goal is to build an interpretable classifier from this knowledge (and from a learning set). Then the scores are assumed to be simple parametric functions from the data space to R with the interpretation that a high value of a score indicates that the datum submitted to the score belongs probably to the class that the score has been designed to detect. Let’s consider a concrete example from our main application domain, aircraft engine monitoring (see [7] for details). We aim here at classifying some short time series (around 150 time points, each series having its own specific length) into different classes (normal signal and different types of anomalies corresponding to some non stationarity in the signal). Domain experts have selected a set of statistical tests as scores. For instance, the Mann-Whitney U test can be used to reject the null hypothesis that two populations are identical. It can be applied to a time series by selecting a potential break point in the series tb and a window size w, and by considering the w/2 points before tb as the first population and the w/2 points after tb as the second population. The score is the p-value of the U test applied to those populations: a high value leads to not rejecting the null hypothesis and thus is an indication that the time series belongs to “no anomaly” class. Notice that the parameters of the score are here the potential break point tb and the window size w. See [7] for other examples. While the experts can design scores, they are seldom able to provide more than hints about the parameters and the thresholds (i.e. when to consider that the score is “high enough”). In addition, the scores are generally no sufficient alone and several of them should be combined to achieve acceptable classification rates. We proposed in [7] to address this problem via feature selection using the filter mRMR approach [5]. The main idea, recalled in Section 2, consists in ∗T. Rabenoro is supported by a grant from Snecma, Safran Group. turning the scores into a large set of redundant binary features and in using a feature selection method to keep useful ones. This has the effect of finding good parameters and thresholds for the scores while retaining a reasonable number of scores, easing interpretation of the decision made by a Naive Bayes Classifier (NBC) built on them. In [7], the selection is done by a filter method. We investigate in the present paper wrapper based approaches. 2 From scores to binary indicators We assume given a training set (Xi , Yi)1≤i≤N where the observations space X can be arbitrary while the target space is a finite set of classes, Y = {1, . . . , K}. We are also given a set of Q parametric scores, (sq)1≤q≤Q. Each sq is a function from X × Wq to R, where Wq is the parameter space of the score. The main constraint of our context is that experts only allow score results to be used by the classifier. In addition, the semantic of the scores means that only decisions of the form sq(Xi , wq) ≤ λq are really meaningful. We propose to transform this set of scores into a much larger set of binary indicators. This is done by choosing for each score a finite subset of Wq, {w 1 q , . . . , w pq q } and a finite set of thresholds {λ 1 q , . . . , λtq q }, and by defining pq × tq indicator functions by I p,t q (X) = Isq(X,wp q )≤λt q . This can be seen as a form of grid search in the “score space” in the sense that tuning the scores to the data set can be done indirectly by selecting relevant binary indicators (a similar principle is used in e.g. [1]).